{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "african-welding",
   "metadata": {},
   "source": [
    "## Infer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "proud-result",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "nvcc: NVIDIA (R) Cuda compiler driver\n",
      "Copyright (c) 2005-2019 NVIDIA Corporation\n",
      "Built on Sun_Jul_28_19:07:16_PDT_2019\n",
      "Cuda compilation tools, release 10.1, V10.1.243\n"
     ]
    }
   ],
   "source": [
    "!nvcc -V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "convertible-cisco",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import sys, subprocess\n",
    "subprocess.call([sys.executable, '-m', 'pip', 'install', 'gluonnlp', 'torch', 'sentencepiece', 'tqdm', \n",
    "                 'onnxruntime', 'transformers', 'git+https://git@github.com/SKTBrain/KoBERT.git@master'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-demand",
   "metadata": {},
   "source": [
    "## KoBERT 라이브러리 등 로딩\n",
    "\n",
    "만약에 `import model` 에서 에러가 발생할 경우에 Kernel 리스타트 하세요."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ruled-richards",
   "metadata": {},
   "outputs": [],
   "source": [
    "import io, os\n",
    "import random\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mxnet as mx\n",
    "from mxnet.gluon import nn, rnn\n",
    "from mxnet import nd, gluon, autograd\n",
    "import gluonnlp as nlp\n",
    "import time\n",
    "import itertools\n",
    "import random\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.path.join(os.getcwd(), 'src'))\n",
    "\n",
    "from model import get_mxnet_kobert_model\n",
    "from kobert.utils import get_tokenizer\n",
    "from bert import BERTDatasetTransform, BERTDataset, BERTClassifier\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legitimate-stupid",
   "metadata": {},
   "source": [
    "## 사용할 GPU 할당"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "drawn-resident",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of GPUS: 4\n",
      "GPU is assigned\n"
     ]
    }
   ],
   "source": [
    "num_gpus = mx.context.num_gpus()\n",
    "ctx = mx.cpu(0)\n",
    "print(\"Number of GPUS:\" , num_gpus)\n",
    "if num_gpus > 0:\n",
    "    ctx = mx.gpu(0)\n",
    "    print(\"GPU is assigned\")\n",
    "else:\n",
    "    ctx = mx.cpu(0)\n",
    "    print(\"CPU is assigned\")    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-thriller",
   "metadata": {},
   "source": [
    "## KoBERT 모델 및 vocab 로딩"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "smart-andrews",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n",
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "bert_base, vocab = get_mxnet_kobert_model(use_decoder=False, \n",
    "                                          use_classifier=False, \n",
    "                                          ctx=ctx)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "authentic-grocery",
   "metadata": {},
   "source": [
    "## Sentence Classification Classifier 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "intellectual-newsletter",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "num of classes:  2\n"
     ]
    }
   ],
   "source": [
    "all_labels = ['0','1'] \n",
    "param_path = 'model_save/net_nsmc.params'\n",
    "\n",
    "def get_bert_classifier(bert_base, classes, ctx, model_params_path):\n",
    "    num_classes = len(classes)\n",
    "    print(\"num of classes: \", num_classes)\n",
    "    bert_classifier = nlp.model.BERTClassifier(bert_base, \n",
    "                                               num_classes=num_classes, \n",
    "                                               dropout=0.5)\n",
    "\n",
    "    # Only need to initialize the classifier layer.\n",
    "    bert_classifier.classifier.initialize(init= mx.init.Normal(0.02), ctx= ctx)\n",
    "    bert_classifier.hybridize(static_alloc=True)\n",
    "    bert_classifier.load_parameters(model_params_path)    \n",
    "\n",
    "    return bert_classifier\n",
    "\n",
    "ko_sent_sims_classifier = get_bert_classifier(bert_base, \n",
    "                                          all_labels, \n",
    "                                          ctx, \n",
    "                                          param_path)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "stretch-anime",
   "metadata": {},
   "source": [
    "## 토큰나이저 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "consecutive-monitoring",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "using cached model\n"
     ]
    }
   ],
   "source": [
    "tokenizer = get_tokenizer() # kobert 토큰나이저\n",
    "kobert_tokenizer = nlp.data.BERTSPTokenizer(tokenizer, vocab, lower=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bearing-proposal",
   "metadata": {},
   "source": [
    "## Data 준비"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "utility-booth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['한 소녀가 머리를 스타일링하고 있다.', '한 소녀가 머리를 빗고 있다.', '0']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_test = nlp.data.TSVDataset('preproc/test/test.tab', \n",
    "                                     field_indices=[5,6,7], \n",
    "                                     num_discard_samples=1)\n",
    "dataset_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "planned-commonwealth",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([   2, 4955, 2826, 5330, 2008, 6116, 2939, 6139, 7788, 3862,  517,\n",
       "          54,    3, 4955, 2826, 5330, 2008, 6116,  517, 6455, 5439, 3862,\n",
       "         517,   54,    3,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1,    1,    1,    1,    1,    1,    1,    1,    1,    1,    1,\n",
       "           1], dtype=int32),\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "        1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int32),\n",
       " array(25, dtype=int32),\n",
       " array([0], dtype=int32))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from bert2 import data\n",
    "vocabulary = vocab\n",
    "def transform_bert_input_type(dataset, idx, bert_tokenizer, max_seq_length=100, pair=True):\n",
    "    '''\n",
    "    자연어 입력값인 sentence1, sentence2, label 을\n",
    "    아래와 같은 버트 입력 형태로 변경\n",
    "    token_id\n",
    "    segment_id\n",
    "    valid_length\n",
    "    label\n",
    "    '''\n",
    "    # The labels for the two classes [(0 = not similar) or  (1 = similar)]\n",
    "    all_labels = [\"0\", \"1\"]\n",
    "\n",
    "    # whether to transform the data as sentence pairs.\n",
    "    # for single sentence classification, set pair=False\n",
    "    # for regression task, set class_labels=None\n",
    "    # for inference without label available, set has_label=False\n",
    "    pair = True\n",
    "    transform = data.transform.BERTDatasetTransform(bert_tokenizer, max_seq_length,\n",
    "                                                    class_labels=all_labels,\n",
    "                                                    has_label=True,\n",
    "                                                    pad=True,\n",
    "                                                    pair=pair)    \n",
    "\n",
    "    data_train = dataset.transform(transform)\n",
    "\n",
    "    return data_train\n",
    "    \n",
    "\n",
    "data_test = transform_bert_input_type(dataset_test, 0, kobert_tokenizer)\n",
    "data_test[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "second-concord",
   "metadata": {},
   "source": [
    "## 샘플 추론"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "higher-freeware",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "@@@ INCORRECT Prediction @@@ \n",
      "######### 문장1 , 문장2, 유사도 [0: No, 1: Yes] ########\n",
      "['한 소녀가 머리를 스타일링하고 있다.', '한 소녀가 머리를 빗고 있다.', '0']\n",
      "### Token ID ###\n",
      "[   2 4955 2826 5330 2008 6116 2939 6139 7788 3862  517   54    3 4955\n",
      " 2826 5330 2008 6116  517 6455 5439 3862  517   54    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "### Logit: 마지막 2개의 뉴런의 값  [0:유사 안함, 1: 유사] ### \n",
      "[[-1.6010176  1.6851689]]\n",
      "<NDArray 1x2 @gpu(0)>\n",
      "\n",
      "\n",
      "### Probability: 마지막 2개의 확률 값 [0:유사 안함, 1: 유사]  ### \n",
      "[0.03604813 0.9639519 ]\n",
      "<NDArray 2 @gpu(0)>\n",
      "\n",
      "\n",
      "Actual Value, Pred Value: 0 , 1\n",
      "\n",
      "\n",
      "\n",
      "@@@ INCORRECT Prediction @@@ \n",
      "######### 문장1 , 문장2, 유사도 [0: No, 1: Yes] ########\n",
      "['두 얼룩말이 열린 필드에서 놀고 있다.', '두 얼룩말이 들판에서 놀고 있다.', '1']\n",
      "### Token ID ###\n",
      "[   2 1773  517 6870 6097 6160 7096 3364  517 7775 6903 1504 5439 3862\n",
      "  517   54    3 1773  517 6870 6097 6160 7096 1801 7688 6903 1504 5439\n",
      " 3862  517   54    3    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "### Logit: 마지막 2개의 뉴런의 값  [0:유사 안함, 1: 유사] ### \n",
      "[[ 0.2883763 -0.5784207]]\n",
      "<NDArray 1x2 @gpu(0)>\n",
      "\n",
      "\n",
      "### Probability: 마지막 2개의 확률 값 [0:유사 안함, 1: 유사]  ### \n",
      "[0.7040788 0.2959212]\n",
      "<NDArray 2 @gpu(0)>\n",
      "\n",
      "\n",
      "Actual Value, Pred Value: 1 , 0\n",
      "\n",
      "\n",
      "\n",
      "@@@ INCORRECT Prediction @@@ \n",
      "######### 문장1 , 문장2, 유사도 [0: No, 1: Yes] ########\n",
      "['한 어린 소년이 노래를 부르고 기타를 치고 있다.', '한 남자가 노래를 부르고 기타를 연주하고 있다.', '0']\n",
      "### Token ID ###\n",
      "[   2 4955 3233 2822 5712 7096 1479 6116 2432 5439 1306 6116  517 7484\n",
      " 3862  517   54    3 4955 1423 5330 1479 6116 2432 5439 1306 6116 3332\n",
      " 7276 7788 3862  517   54    3    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "### Logit: 마지막 2개의 뉴런의 값  [0:유사 안함, 1: 유사] ### \n",
      "[[-1.343461   1.3071531]]\n",
      "<NDArray 1x2 @gpu(0)>\n",
      "\n",
      "\n",
      "### Probability: 마지막 2개의 확률 값 [0:유사 안함, 1: 유사]  ### \n",
      "[0.06595116 0.9340489 ]\n",
      "<NDArray 2 @gpu(0)>\n",
      "\n",
      "\n",
      "Actual Value, Pred Value: 0 , 1\n",
      "\n",
      "\n",
      "\n",
      "@@@ INCORRECT Prediction @@@ \n",
      "######### 문장1 , 문장2, 유사도 [0: No, 1: Yes] ########\n",
      "['거북이가 물속에서 헤엄치고 있다.', '거북이가 물속에서 걷고 있다.', '1']\n",
      "### Token ID ###\n",
      "[   2  862 6412 7096 5330 2135 6615 6903 5046 6872 7484 3862  517   54\n",
      "    3  862 6412 7096 5330 2135 6615 6903  888 5439 3862  517   54    3\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "### Logit: 마지막 2개의 뉴런의 값  [0:유사 안함, 1: 유사] ### \n",
      "[[ 1.0726725 -1.4249123]]\n",
      "<NDArray 1x2 @gpu(0)>\n",
      "\n",
      "\n",
      "### Probability: 마지막 2개의 확률 값 [0:유사 안함, 1: 유사]  ### \n",
      "[0.9239723  0.07602766]\n",
      "<NDArray 2 @gpu(0)>\n",
      "\n",
      "\n",
      "Actual Value, Pred Value: 1 , 0\n",
      "\n",
      "\n",
      "\n",
      "@@@ INCORRECT Prediction @@@ \n",
      "######### 문장1 , 문장2, 유사도 [0: No, 1: Yes] ########\n",
      "['한 여성이 휴대폰으로 통화하고 있다.', '한 남자와 여자가 전화로 이야기하고 있다.', '1']\n",
      "### Token ID ###\n",
      "[   2 4955 3312 7096 5194 7078 4758 7788 3862  517   54    3 4955 1423\n",
      " 6983 3318 5330 4064 6079 3714 7788 3862  517   54    3    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1    1    1    1    1    1    1    1    1    1    1    1    1\n",
      "    1    1]\n",
      "### Logit: 마지막 2개의 뉴런의 값  [0:유사 안함, 1: 유사] ### \n",
      "[[ 1.5568769 -2.295405 ]]\n",
      "<NDArray 1x2 @gpu(0)>\n",
      "\n",
      "\n",
      "### Probability: 마지막 2개의 확률 값 [0:유사 안함, 1: 유사]  ### \n",
      "[0.9792102  0.02078984]\n",
      "<NDArray 2 @gpu(0)>\n",
      "\n",
      "\n",
      "Actual Value, Pred Value: 1 , 0\n",
      "\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def eval_sample(sent_classifier, dataset_test, data_test, num_test=3, verbose=False):\n",
    "    # num_test = len(data_test)\n",
    "    # num_test = 3\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    def print_detail(raw_input, bert_input, logit, prob, actual_label, pred_label):\n",
    "        print(\"######### 문장1 , 문장2, 유사도 [0: No, 1: Yes] ########\")\n",
    "        print(raw_input)    \n",
    "        print(\"### Token ID ###\")        \n",
    "        print(bert_input)\n",
    "        print(\"### Logit: 마지막 2개의 뉴런의 값  [0:유사 안함, 1: 유사] ###\", logit)   \n",
    "        print('\\n')\n",
    "        print(\"### Probability: 마지막 2개의 확률 값 [0:유사 안함, 1: 유사]  ###\", prob)   \n",
    "        print('\\n')\n",
    "        print(f\"Actual Value, Pred Value: {actual_label} , {pred_label}\")\n",
    "        print('\\n\\n')        \n",
    "    \n",
    "    for i in range(num_test):   \n",
    "        input_ids = mx.nd.array([data_test[i][0]])\n",
    "        token_type_ids = mx.nd.array([data_test[i][1]])\n",
    "        valid_length = mx.nd.array([data_test[i][2]])\n",
    "\n",
    "        input_ids = input_ids.as_in_context(ctx)\n",
    "        token_type_ids = token_type_ids.as_in_context(ctx)\n",
    "        valid_length = valid_length.as_in_context(ctx)\n",
    "\n",
    "        logit = sent_classifier.forward(input_ids, token_type_ids, valid_length)\n",
    "        prob = mx.nd.softmax(logit[0])\n",
    "        k = [1]\n",
    "        pred_label = prob.argsort()[-k[-1]:][::-1].astype(int).asnumpy()[0] # Predict Label\n",
    "\n",
    "        actual_label = int(data_test[i][-1]) # Actual Value\n",
    "        if actual_label != pred_label:\n",
    "            print(\"@@@ INCORRECT Prediction @@@ \")\n",
    "            print_detail(dataset_test[i], data_test[i][0], logit, prob, actual_label, pred_label)\n",
    "            \n",
    "        elif verbose:\n",
    "            print(\"%%% CORRECT Prediction %%%%\")            \n",
    "            print_detail(dataset_test[i], data_test[i][0], logit, prob, actual_label, pred_label)\n",
    "\n",
    "            \n",
    "            \n",
    "\n",
    "eval_sample(ko_sent_sims_classifier, dataset_test, data_test, num_test=50, verbose=False)        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "continental-trial",
   "metadata": {},
   "source": [
    "## 토큰 분석\n",
    "문장이 어떻게 토큰화 되었는지를 확인 함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "crucial-representation",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['한 무리의 남자들이 해변에서 축구를 한다.', '한 무리의 소년들이 해변에서 축구를 하고 있다.', '1']\n",
      "[CLS]\n",
      "▁한\n",
      "▁무리\n",
      "의\n",
      "▁남자\n",
      "들이\n",
      "▁해\n",
      "변\n",
      "에서\n",
      "▁축구\n",
      "를\n",
      "▁한다\n",
      "▁\n",
      ".\n",
      "[SEP]\n",
      "▁한\n",
      "▁무리\n",
      "의\n",
      "▁소\n",
      "년\n",
      "들이\n",
      "▁해\n",
      "변\n",
      "에서\n",
      "▁축구\n",
      "를\n",
      "▁하고\n",
      "▁있다\n",
      "▁\n",
      ".\n",
      "[SEP]\n",
      "[PAD]\n",
      "[PAD]\n"
     ]
    }
   ],
   "source": [
    "idx2token = vocab.idx_to_token\n",
    "sample_id = 1\n",
    "print(dataset_test[sample_id])\n",
    "for i, idx in enumerate(data_test[sample_id][0]):\n",
    "    print(idx2token[idx])    \n",
    "    if i == 32:\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "brilliant-portfolio",
   "metadata": {},
   "source": [
    "## 종합 테스트"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "convinced-commissioner",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               precision    recall  f1-score   support\n",
      "\n",
      "0:Non-Similar       0.83      0.79      0.81       706\n",
      "    1:Similar       0.79      0.83      0.81       670\n",
      "\n",
      "     accuracy                           0.81      1376\n",
      "    macro avg       0.81      0.81      0.81      1376\n",
      " weighted avg       0.81      0.81      0.81      1376\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, dataset_test, data_test, labels, ctx):\n",
    "    \n",
    "    num_test = len(data_test)\n",
    "    # num_test = 10\n",
    "\n",
    "    y_true = []\n",
    "    y_pred = []\n",
    "    \n",
    "    for i in range(num_test):   \n",
    "        # print(dataset_test[i])\n",
    "        \n",
    "        input_ids = mx.nd.array([data_test[i][0]])\n",
    "        token_type_ids = mx.nd.array([data_test[i][1]])\n",
    "        valid_length = mx.nd.array([data_test[i][2]])\n",
    "\n",
    "        input_ids = input_ids.as_in_context(ctx)\n",
    "        token_type_ids = token_type_ids.as_in_context(ctx)\n",
    "        valid_length = valid_length.as_in_context(ctx)\n",
    "\n",
    "        tid_true = int(data_test[i][-1])\n",
    "        logit = ko_sent_sims_classifier.forward(input_ids, token_type_ids, valid_length)\n",
    "        # print(\"last logit: \", logit)\n",
    "        prob = mx.nd.softmax(logit[0])\n",
    "        # print(\"prob: \", prob)\n",
    "        k = [1]\n",
    "        topk_pred = prob.argsort()[-k[-1]:][::-1].astype(int).asnumpy()\n",
    "        y_true.append(tid_true)\n",
    "        y_pred.append(topk_pred[0])\n",
    "        \n",
    "    from sklearn.metrics import classification_report, accuracy_score, precision_score, recall_score, f1_score  \n",
    "    prec = precision_score(y_true, y_pred, labels=labels, average=None)\n",
    "    f1 = f1_score(y_true, y_pred, labels=labels, average=None)\n",
    "    rec = recall_score(y_true, y_pred, labels=labels, average=None)    \n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    print(classification_report(y_true, y_pred, target_names = ['0:Non-Similar','1:Similar']))\n",
    "\n",
    "\n",
    "labels=[0,1]\n",
    "evaluate_model(ko_sent_sims_classifier, dataset_test, data_test, labels, ctx)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "improved-pulse",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_mxnet_p36",
   "language": "python",
   "name": "conda_mxnet_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
